{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy :: 1.14.0\n",
      "cv2 ::  4.1.1\n",
      "tensorflow ::  2.1.0\n"
     ]
    }
   ],
   "source": [
    "# These are required libraries and dependencies \n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the required info\n",
    "TRAIN_DIR = './computer_vision'\n",
    "IMG_SIZE = 50\n",
    "class_names = ['category1', 'category2', 'category3', 'category4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:00<00:00, 200.58it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 281.90it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 292.82it/s]\n",
      "100%|██████████| 20/20 [00:00<00:00, 289.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Traning dataset creating method from the local dataset\n",
    "training_data = []\n",
    "\n",
    "def create_training_data():\n",
    "    for category in class_names:  \n",
    "\n",
    "        path = os.path.join(TRAIN_DIR,category)  \n",
    "        class_num = class_names.index(category) \n",
    "        for img in tqdm(os.listdir(path)):  # iterate over each image\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path,img) ,cv2.IMREAD_GRAYSCALE)  # convert to array\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))  # resize to normalize data size\n",
    "                training_data.append([new_array, class_num])  # add this to our training_data\n",
    "            except Exception as e:  # in the interest in keeping the output clean...\n",
    "                print(e)\n",
    "                pass\n",
    "            \n",
    "create_training_data()\n",
    "\n",
    "print(len(training_data))\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From training data extract the features and labels\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for features,label in training_data:\n",
    "    X.append(features)\n",
    "    y.append(label)\n",
    "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-106c449325c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpickle_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X.pickle\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpickle_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# save the labels and features of the training dataset into the pickle files\n",
    "import pickle\n",
    "\n",
    "pickle_out = open(\"X.pickle\",\"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"y.pickle\",\"wb\")\n",
    "pickle.dump(y, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_in = open(\"X.pickle\",\"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"y.pickle\",\"rb\")\n",
    "y = pickle.load(pickle_in)\n",
    "\n",
    "X = X/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The CNN model structure \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), input_shape=X.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\n",
    "model.add(Flatten())  \n",
    "\n",
    "model.add(Dense(128))\n",
    "\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 56 samples, validate on 24 samples\n",
      "Epoch 1/30\n",
      "56/56 [==============================] - 0s 8ms/sample - loss: 1.0184 - accuracy: 0.6071 - val_loss: 1.0080 - val_accuracy: 0.8333\n",
      "Epoch 2/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.9289 - accuracy: 0.7679 - val_loss: 0.9409 - val_accuracy: 0.6667\n",
      "Epoch 3/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.9049 - accuracy: 0.7321 - val_loss: 0.9001 - val_accuracy: 0.6667\n",
      "Epoch 4/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8532 - accuracy: 0.7679 - val_loss: 0.8762 - val_accuracy: 0.6667\n",
      "Epoch 5/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8159 - accuracy: 0.7679 - val_loss: 0.8553 - val_accuracy: 0.6667\n",
      "Epoch 6/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8074 - accuracy: 0.7679 - val_loss: 0.8708 - val_accuracy: 0.6667\n",
      "Epoch 7/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8371 - accuracy: 0.7679 - val_loss: 0.8471 - val_accuracy: 0.9167\n",
      "Epoch 8/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8098 - accuracy: 0.8750 - val_loss: 0.8472 - val_accuracy: 0.9167\n",
      "Epoch 9/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8089 - accuracy: 0.7679 - val_loss: 0.8536 - val_accuracy: 0.7083\n",
      "Epoch 10/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8175 - accuracy: 0.7857 - val_loss: 0.8436 - val_accuracy: 0.8333\n",
      "Epoch 11/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8259 - accuracy: 0.8214 - val_loss: 0.8794 - val_accuracy: 0.8750\n",
      "Epoch 12/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8424 - accuracy: 0.9643 - val_loss: 0.8420 - val_accuracy: 1.0000\n",
      "Epoch 13/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8963 - accuracy: 0.8571 - val_loss: 0.9315 - val_accuracy: 0.6667\n",
      "Epoch 14/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8750 - accuracy: 0.7321 - val_loss: 0.8598 - val_accuracy: 0.7083\n",
      "Epoch 15/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8336 - accuracy: 0.9107 - val_loss: 0.8361 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8227 - accuracy: 0.9643 - val_loss: 0.8313 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8329 - accuracy: 0.8750 - val_loss: 0.8313 - val_accuracy: 0.9583\n",
      "Epoch 18/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8202 - accuracy: 0.9643 - val_loss: 0.8538 - val_accuracy: 0.9583\n",
      "Epoch 19/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8374 - accuracy: 0.9643 - val_loss: 0.8425 - val_accuracy: 0.9583\n",
      "Epoch 20/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8385 - accuracy: 0.9643 - val_loss: 0.8402 - val_accuracy: 0.9583\n",
      "Epoch 21/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8328 - accuracy: 0.9643 - val_loss: 0.8315 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8203 - accuracy: 0.9643 - val_loss: 0.8618 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8168 - accuracy: 0.9821 - val_loss: 0.9031 - val_accuracy: 0.9167\n",
      "Epoch 24/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8202 - accuracy: 0.9821 - val_loss: 0.8578 - val_accuracy: 1.0000\n",
      "Epoch 25/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8153 - accuracy: 0.9821 - val_loss: 0.8580 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8233 - accuracy: 0.9821 - val_loss: 0.8579 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8193 - accuracy: 0.9821 - val_loss: 0.8258 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8078 - accuracy: 0.9643 - val_loss: 0.8510 - val_accuracy: 0.9167\n",
      "Epoch 29/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8444 - accuracy: 0.8393 - val_loss: 0.8758 - val_accuracy: 0.7500\n",
      "Epoch 30/30\n",
      "56/56 [==============================] - 0s 3ms/sample - loss: 0.8442 - accuracy: 0.8571 - val_loss: 0.8510 - val_accuracy: 0.9167\n",
      "INFO:tensorflow:Assets written to: simple_image_classifer_sagar_deyagond_CNN_model/assets\n"
     ]
    }
   ],
   "source": [
    "# compile the model and train the model and save\n",
    "y = np.array(y)\n",
    "\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model. fit(X, y, batch_size=8 , epochs=30, validation_split=0.3)\n",
    "model.save('simple_image_classifer_sagar_deyagond_CNN_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
